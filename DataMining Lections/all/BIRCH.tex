
\subsection{BIRCH}

BIRCH "--- {\it  Balanced Iterative Reducing and Clustering using Hierarchies.}

{\bf Идея метода:} построить иерархию кластеров, которая позволит хранить
ограниченное количество данных в виде агрегатов.

\begin{itemize}
\item локальность: каждая точка <<кластеризуется>> без сканирования всех других точек или имеющихся кластеров;
\item выбросы: точки в <<густонаселенных>> регионах принадлежат кластерам, а в <<малонаселенных>> "--- к выбросам;
\item экономность: используется вся доступная память, при этом минимизируется I/O;
\item масштабируемость: при определенных условиях обучается <<онлайн>> и требует единственного прохода по данным.
\end{itemize}

\subsubsection{Меры компактности кластера}
\begin{itemize}
\item Центроид 
\[
x_0 = \frac{1}{N} \sum\limits_{i=1}^{N} x_i;
\]
\item Радиус
\[
R = \frac{1}{N} \sum\limits_{i=1}^{N} d(x_i,x_0);
\]
\item Диаметр
\[
D = \frac{1}{N(N-1)} \sum\limits_{i=1}^{N}\sum\limits_{j=1}^{N} d(x_i,x_j).
\]
\end{itemize}

В начале работы алгоритма все объекты принадлежат одному кластеру, который на последующих шагах делится на меньшие кластеры, в результате образуется последовательность расщепляющих групп.

В этом алгоритме предусмотрен двухэтапный процесс кластеризации.

\subsubsection{Clustering Feature}
{\it Clustering feature} "--- это объект, содержащий сжатую информацию о кластере.

\begin{Def}
 Пусть кластер $C$ содержит $N$ d-мерных объектов $x_i$. Clustering feature ($CF$) для $C$ определяется как тройка $CF = (N,LS,SS)$, где
 \[
 LS =  \sum\limits_{i=1}^{N} x_i, \qquad SS = \sum\limits_{i=1}^{N} x_i^2.
 \]
\end{Def}

\begin{Ut}
Пусть $CF_1 = (N_1, LS_1, SS_1)$ и $CF_2 = (N_2, LS_2, SS_2)$ "--- $CF$ для кластеров $C_1$ и $C_2$. Тогда CF для кластера, полученного слиянием $C_1$ и $C_2$, определяется как
\[
CF = (N_1 + N_2, LS_1 + LS_2, SS_1 + SS_2).
\]
\end{Ut}

\subsubsection{CF-Tree}
\begin{Def}
CF-Tree "--- это взвешенно сбалансированное дерево, состоящее из множества кластерных элементов (clustering feature). \\
Балансирующие параметры:
\begin{itemize}
\item B – коэффициент разветвление (максимальное количество детей у внутреннего узла);
\item L – максимальное количество детей у листа;
\item T – пороговая велечина, а именно максимальная компактность (R или D) ребенка листа( т.е. лист не может быть бльше, чем это T).
\end{itemize}
Каждый нелистьевой узел данного дерева имеет не более чем B вхождений узлов следующей формы: $[CF_i, Child_i]$, где $i = 1, 2, \dots, B$ ($Child_i$ – указатель на $i$-й дочерний узел).\\
Каждый листьевой узел имеет ссылку на два соседних узла. Кластер состоящий из элементов листьевого узла должен удовлетворять следующему условию: диаметр или радиус полученного кластера должен быть не более пороговой величины T.
\end{Def}

\begin{Zam}
При разделении узла выбираем две наиболее удаленные CF и лепим к ним ближайшие.
\end{Zam}
\subsubsection{Итоги}
\begin{itemize}
\item Назначение: кластеризация очень больших наборов числовых данных. 
\item Ограничения: работа с только числовыми данными. 
\item Достоинства:
\begin{itemize} 
\item[+] двухступенчатая кластеризация, 
\item[+] кластеризация больших объемов данных, 
\item[+] работает на ограниченном объеме памяти, 
\item[+] является локальным алгоритмом, 
\item[+] может работать при одном сканировании входного набора данных,
\item[+] использует тот факт, что данные неодинаково распределены по пространству,  
\item[+] обрабатывает области с большой плотностью как единый кластер.
\end{itemize} 
\item Недостатки: 
\begin{itemize}
\item работа с только числовыми данными, 
\item хорошо выделяет только кластеры сферической формы, 
\item есть необходимость в задании пороговых значений.
\end{itemize} 
\end{itemize} 
